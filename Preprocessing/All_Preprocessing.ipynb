{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def None_josa(sentence_list):    # 형태소 분석기와 같이 사용\n",
    "    sentence_None_josa = []\n",
    "    for line in sentence_list:\n",
    "        line = okt.pos(line)\n",
    "        etc = []\n",
    "        for word in line:\n",
    "            if word[1] != 'Josa':\n",
    "                etc.append(word[0])\n",
    "        sentence_None_josa.append(etc)\n",
    "    return sentence_None_josa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "\n",
    "def special_char(sentence_list):      # 형태소 분석기나 자모 단위 전의 preprocessing\n",
    "    spec_sym = re.compile('[ㄱ-ㅣ가-힣a-zA-Z0-9\\s]')\n",
    "    sentence_special = copy.copy(sentence_list)\n",
    "    return_sentence = []\n",
    "    \n",
    "    special = []\n",
    "    for i in range(len(sentence_special)):\n",
    "        sentence_special[i] = re.sub(spec_sym,'',sentence_special[i])\n",
    "        for ch in sentence_special[i]:\n",
    "            special.append(ch)\n",
    "\n",
    "    for line in sentence_list:\n",
    "        etc = []\n",
    "        for char in line:\n",
    "            if char not in special:\n",
    "                etc.append(char)\n",
    "        return_sentence.append(''.join(etc))\n",
    "        \n",
    "    return return_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def Nouns(sentence_list):    # 형태소 분석기와 같이 사용\n",
    "    sentence_Nouns = []\n",
    "    for line in sentence_list:\n",
    "        line = okt.pos(line)\n",
    "        etc = []\n",
    "        for word in line:\n",
    "            if word[1][0] == 'N':\n",
    "                etc.append(word[0])\n",
    "        sentence_Nouns.append(etc)\n",
    "    return sentence_Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def Count_100(sentence_list):    # 형태소 분석기와 같이 사용\n",
    "    all_word = []\n",
    "    for line in sentence_list:\n",
    "        line = okt.morphs(line)\n",
    "        for word in line:\n",
    "            all_word.append(word)\n",
    "    all_word_count = Counter(all_word)\n",
    "\n",
    "    remove_100 = []\n",
    "    for i in all_word_count.most_common(n=100):\n",
    "        remove_100.append(i[0])\n",
    "    \n",
    "    remove_word_sentence = []\n",
    "    \n",
    "    for line in sentence_list:\n",
    "        line = okt.morphs(line)\n",
    "        etc = []\n",
    "        for word in line:\n",
    "            if word not in remove_100:\n",
    "                etc.append(word)\n",
    "        remove_word_sentence.append(etc)\n",
    "    return remove_word_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조사 제거 :  [['아', '더빙', '..', '진짜', '짜증나네요', '목소리'], ['흠', '...', '포스터', '보고', '초딩', '영화', '줄', '....', '오버', '연기', '가볍지', '않구나'], ['너', '무재', '밓었', '다그', '래서', '보는것을', '추천', '다'], ['교도소', '이야기', '구먼', '..', '솔직히', '재미', '없다', '..', '평점', '조정'], ['사이', '몬페', '그', '의', '익살스런', '연기', '돋보였던', '영화', '!', '스파이더맨', '늙어', '보이기만', '했던', '커스틴', '던스트', '너무나도', '이뻐', '보였다']]\n",
      "\n",
      "특수문자 제거 :  ['아 더빙 진짜 짜증나네요 목소리', '흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나', '너무재밓었다그래서보는것을추천한다', '교도소 이야기구먼 솔직히 재미는 없다평점 조정', '사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다']\n",
      "\n",
      "명사만 추출 :  [['더빙', '진짜', '목소리'], ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기'], ['무재', '밓었', '다그', '래서', '추천'], ['교도소', '이야기', '구먼', '재미', '평점', '조정'], ['몬페', '의', '연기', '영화', '스파이더맨', '커스틴', '던스트']]\n",
      "\n",
      "상위 빈도 100개 제거 :  [['더빙', '짜증나네요', '목소리'], ['흠', '포스터', '초딩', '줄', '오버', '조차', '가볍지', '않구나'], ['너', '무재', '밓었', '다그', '래서', '보는것을', '추천'], ['교도소', '이야기', '구먼', '솔직히', '조정'], ['사이', '몬페', '익살스런', '돋보였던', '스파이더맨', '늙어', '보이기만', '했던', '커스틴', '던스트', '너무나도', '이뻐', '보였다']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open('./ratings_train.txt', 'r', encoding='utf-8-sig')\n",
    "\n",
    "sentence = []\n",
    "\n",
    "for idx, line in enumerate(file):\n",
    "    if idx == 0:     # 첫 번째 줄은 열의 label이 들어있는 Line\n",
    "        continue\n",
    "    line = line.split('\\t')\n",
    "    sentence.append(line[1].strip())\n",
    "\n",
    "josa = None_josa(sentence[:1500])\n",
    "spe = special_char(sentence[:1500])\n",
    "noun = Nouns(sentence[:1500])\n",
    "cnt = Count_100(sentence[:1500])\n",
    "    \n",
    "print('조사 제거 : ', josa[:5], end = '\\n\\n')\n",
    "print('특수문자 제거 : ', spe[:5], end = '\\n\\n')\n",
    "print('명사만 추출 : ', noun[:5], end = '\\n\\n')\n",
    "print('상위 빈도 100개 제거 : ', cnt[:5], end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
